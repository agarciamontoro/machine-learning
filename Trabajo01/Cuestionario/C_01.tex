\documentclass[a4paper, 11pt]{article}
\usepackage[cuestionario=1]{estilo}

\begin{document}

    \maketitle

    \section{Ejercicios}

    \begin{ejercicio}
        Identificar, para cada una de las siguientes tareas, qu√© tipo de aprendizaje es el adecuado (supervisado, no supervisado, por refuerzo) y los datos de aprendizaje que deber√≠amos usar. Si una tarea se ajusta a m√°s de un tipo, explicar c√≥mo y describir los datos para cada tipo.
        \begin{itemize}
            \item Categorizar un grupo de animales vertebrados en pajaros, mam√≠feros, reptiles, aves y anfibios.
            \item Clasificaci√≥n autom√°tica de cartas por distrito postal.
            \item Decidir si un determinado √≠ndice del mercado de valores subir√° o bajar√° dentro de un periodo de tiempo fijado.
        \end{itemize}
    \end{ejercicio}


    \begin{ejercicio}
        ¬øCu√°les de los siguientes problemas son m√°s adecuados para una aproximaci√≥n por aprendizaje y cu√°les m√°s adecuados para una aproximaci√≥n por dise√±o? Justificar la decisi√≥n.
        \begin{itemize}
            \item Determinar el ciclo √≥ptimo para las luces de los sem√°foros en un cruce con mucho tr√°fico.
            \item Determinar los ingresos medios de una persona a partir de sus datos de nivel de educaci√≥n, edad, experiencia y estatus social.
            \item Determinar si se debe aplicar una campa√±a de vacunaci√≥n contra una enfermedad.
        \end{itemize}
    \end{ejercicio}

    \begin{ejercicio}
        Construir un problema de aprendizaje desde datos para un problema de selecci√≥n de fruta en una explotaci√≥n agraria (ver transparencias de clase). Identificar y describir cada uno de sus elementos formales. Justificar las decisiones.
    \end{ejercicio}

    \begin{ejercicio}
        Suponga un modelo PLA y un dato $x(t)$ mal clasificado respecto de dicho modelo. Probar que la regla de adaptaci√≥n de pesos del PLA es un movimiento en la direcci√≥n correcta para clasificar bien $x(t)$.
    \end{ejercicio}

    \begin{solucion}
        Sea $(x(t), y(t))$ la muestra mal clasificada respecto del modelo PLA. La siguiente iteraci√≥n nos da un vector de pesos
        \[
        w(t+1) = w(t) + y(t)x(t)
        \]

        Como el dato $x(t)$ est√° mal etiquetado, tenemos que $sign(w^T(t) x(t)) \neq y(t)$, luego podemos concluir que
        \[
        y(t) sign(w^T(t) x(t)) < 0
        \]

        De hecho, como $sign(x) \in \{-1, 1\} \forall x \in \mathbb{R}$, tenemos que
        \[
        y(t) sign(w^T(t) x(t)) = -1
        \]

        Por otro lado, tenemos que
        \begin{align*}
            y(t) w^T(t+1) x(t) &= y(t) (w^T(t) + y(t)x(t)) x(t) = \\
            &= (y(t)w^T(t) + x(t)) x(t) = \\ \comment{Hemos usado que y(t)^2 = 1}
            &= y(t)w^T(t)x(t) + x^2(t) > y(t)w^T(t)x(t)
        \end{align*}

        Tomando signos, tenemos la siguiente desigualdad:
        \[
        sign(y(t) w^T(t+1) x(t)) > sign(y(t)w^T(t)x(t)) = y(t) sign(w^T(t) x(t)) = -1
        \]

        Como la anterior es una desigualdad estricta, podemos concluir que $sign(y(t) w^T(t+1) x(t)) = 1$, luego
        tenemos que
        \[
        y(t) = sign(w^T(t+1) x(t))
        \]
        es decir, la muestra $(x(t), y(t))$ est√° ahora bien etiquetada.
    \end{solucion}


    \begin{ejercicio}
        Considere el enunciado del ejercicio 2 de la secci√≥n FACTIBILIDAD DEL APRENDIZAJE de la relaci√≥n apoyo.
        \begin{itemize}
            \item Si $p = 0.9$, ¬øcu√°l es la probabilidad de que S produzca una hip√≥tesis mejor que C?
            \item ¬øExiste un valor de $p$ para el cual es m√°s probable que C produzca una hip√≥tesis mejor que S?
        \end{itemize}
    \end{ejercicio}


    \begin{ejercicio}
        La desigualdad de Hoeffding modificada nos da una forma de caracterizar el error de generalizaci√≥n con una cota probabil√≠stica
        \[
        \mathbb{P}[\vert E_{out}(g) - E_{in}(g) \vert > \varepsilon] \leq 2 M e^{-2 N^2 \varepsilon}
        \]
        para cualquier $\varepsilon > 0$. Si fijamos $\varepsilon = 0.05$ y queremos que la cota probabil√≠stica $2 M e^{-2 N^2 \varepsilon}$ sea como m√°ximo $0.03$, ¬øcu√°l ser√° el valor m√°s peque√±o de $N$ que verifique estas condiciones si $M = 1$? Repetir para $M = 10$ y para $M = 100$.
    \end{ejercicio}

    \begin{solucion}
        Mirar folio
    \end{solucion}


    \begin{ejercicio}
        Consideremos el modelo de aprendizaje \guillemotleft M-intervalos \guillemotright donde $h \from \mathbb{R} \to \{‚àí1, +1\}$, y $h(x) = +1$ si el punto est√° dentro de cualquiera de $m$ intervalos arbitrariamente elegidos y ‚àí1 en otro caso. ¬øCu√°l es el m√°s peque√±o punto de ruptura para este conjunto de hip√≥tesis?
    \end{ejercicio}

    \begin{solucion}
        Es k = 3, lo pone en las transparencias, pero no s√© por qu√©.    
    \end{solucion}


    \begin{ejercicio}
        Suponga un conjunto de $k^*$ puntos $x_1, x_2 , \dots , x_{k^*}$ sobre los cuales la clase $\mathcal{H}$ implementa $< 2^{k^*}$ dicotom√≠as. ¬øCu√°les de las siguientes afirmaciones son correctas?
        \begin{itemize}
            \item $k^*$ es un punto de ruptura.
            \item $k^*$ no es un punto de ruptura.
            \item Todos los puntos de ruptura son estrictamente mayores que $k^*$.
            \item Todos los puntos de ruptura son menores o iguales a $k^*$
            \item No conocemos nada acerca del punto de ruptura.
        \end{itemize}
    \end{ejercicio}


    \begin{ejercicio}
        Para todo conjunto de $k^*$ puntos, $\mathcal{H}$ implementa $< 2^{k^*}$ dicotom√≠as. ¬øCu√°les de las siguientes afirmaciones son correctas?
        \begin{itemize}
            \item $k^*$ es un punto de ruptura.
            \item $k^*$ no es un punto de ruptura.
            \item Todos los $k \geq k^*$ son puntos de ruptura.
            \item Todos los $k < k^*$ son puntos de ruptura.
            \item No conocemos nada acerca del punto de ruptura.
        \end{itemize}
    \end{ejercicio}



    \begin{ejercicio}
        Si queremos mostrar que $k^*$ es un punto de ruptura, ¬øcu√°les de las siguientes afirmaciones nos servir√≠an para ello?:
        \begin{itemize}
            \item Mostrar que existe un conjunto de $k^*$ puntos $x_1, x_2 , \dots , x_{k^*}$ que $\mathcal{H}$ puede separar ---\emph{shatter}---.
            \item Mostrar que $\mathcal{H}$ puede separar cualquier conjunto de $k^*$ puntos.
            \item Mostrar un conjunto de $k^*$ puntos $x_1, x_2 , \dots , x_{k^*}$ que $\mathcal{H}$ no puede separar.
            \item Mostrar que $\mathcal{H}$ no puede separar ning√∫n conjunto de $k^*$ puntos.
            \item Mostrar que $m_\mathcal{H} (k) = 2^{k^*}$
        \end{itemize}
    \end{ejercicio}


    \begin{ejercicio}
        Para un conjunto $\mathcal{H}$ con $d_{VC} = 10$, ¬øqu√© tama√±o muestral se necesita ---seg√∫n la cota de generalizaci√≥n--- para tener un 95\% de confianza de que el error de generalizaci√≥n sea como mucho $0.05$?
    \end{ejercicio}

    \begin{ejercicio}
        Consideremos un escenario de aprendizaje simple. Supongamos que la dimensi√≥n de entrada es uno. Supongamos que la variable de entrada $x$ est√° uniformemente distribuida en el intervalo $[‚àí1, 1]$ y el conjunto de datos consiste en 2 puntos $\{x1, x2\}$ y que la funci√≥n objetivo es $f(x) = x^2$. Por tanto el conjunto de datos completo es $\mathcal{D} = \{(x_1 , x_1^2), (x_2, x_2^2)\}$. El algoritmo de aprendizaje devuelve la l√≠nea que ajusta estos dos puntos como $g$; es decir, \mathcal{H} consiste en funciones de la forma $h(x) = ax + b$.
        \begin{itemize}
            \item Dar una expresi√≥n anal√≠tica para la funci√≥n promedio $\bar{g}(x)$.
            \item Calcular analiticamente los valores de $E_{out}$, \emph{bias} y \emph{var}.
        \end{itemize}
    \end{ejercicio}


    \section{Bonus}

    \begin{bonus}
        Considere el enunciado del ejercicio 2 de la secci√≥n ERROR Y RUIDO de la relaci√≥n de apoyo.
        \begin{itemize}
            \item Si su algoritmo busca la hip√≥tesis $h$ que minimiza la suma de los valores absolutos de los errores de la muestra,
            \[
            E_{in}(h) = \sum_{n=1}^N \vert h - y_n \vert
            \]
            entonces mostrar que la estimaci√≥n ser√° la mediana de la muestra, $h_{med}$ ---cualquier valor que deje la mitad de la muestra a su derecha y la mitad a su izquierda---.
            \item Suponga que $y_N$ es modificado como $y_N + \varepsilon$, donde $\varepsilon \to \infty$. Obviamente el valor de $y_N$ se convierte en un punto muy alejado de su valor original. ¬øC√≥mo afecta esto a los estimadores dados por $h_{mean}$ y $h_{med}$?
        \end{itemize}
    \end{bonus}



    \begin{bonus}
        Considere el ejercicio 12.
        \begin{itemize}
            \item Describir un experimento que podamos ejecutar para determinar ---num√©ricamente--- $\bar{g}(x)$, $E_{out}$, \emph{bias} y \emph{var}.
            \item Ejecutar el experimento y dar los resultados. Comparar $E_{out}$ con $bias+var$. Dibujar en unos mismos ejes $\bar{g}(x)$, $E_{out}$ y $f(x)$.
        \end{itemize}
    \end{bonus}

\end{document}
