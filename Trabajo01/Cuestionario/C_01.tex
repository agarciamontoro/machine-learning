\documentclass[a4paper, 11pt]{article}
\usepackage[cuestionario=1]{estilo}

\begin{document}

    \maketitle

    \section{Ejercicios}

    \begin{ejercicio}
        Identificar, para cada una de las siguientes tareas, qu√© tipo de aprendizaje es el adecuado (supervisado, no supervisado, por refuerzo) y los datos de aprendizaje que deber√≠amos usar. Si una tarea se ajusta a m√°s de un tipo, explicar c√≥mo y describir los datos para cada tipo.
        \begin{itemize}
            \item Categorizar un grupo de animales vertebrados en p√°jaros, mam√≠feros, reptiles, aves y anfibios.
            \item Clasificaci√≥n autom√°tica de cartas por distrito postal.
            \item Decidir si un determinado √≠ndice del mercado de valores subir√° o bajar√° dentro de un periodo de tiempo fijado.
        \end{itemize}
    \end{ejercicio}

    \begin{solucion}
        \emph{Categorizar un grupo de animales vertebrados en p√°jaros, mam√≠feros, reptiles, aves y anfibios.}

        La categorizaci√≥n autom√°tica de un grupo de animales vertebrados en sus diferentes clases puede abordarse como un problema de aprendizaje supervisado. Si tenemos una manera de describir un animal, ya sea con una imagen o, por ejemplo, una descripci√≥n cuantitativa de sus cualidades anat√≥micas, necesitaremos una muestra previamente clasificada para poder entrenar nuestro algoritmo de aprendizaje. Abordar este problema con aprendizaje no supervisado no tendr√≠a sentido, ya que tenemos una forma clara ---aunque no definida anal√≠ticamente, si as√≠ fuera ser√≠a m√°s sensato resolver este problema mediante dise√±o--- de diferenciar entre clases; no usar esa informaci√≥n es perder oportunidades. Por √∫ltimo, el aprendizaje por refuerzo no tiene sentido en este caso; no hay definida una estructura de acti√≥n y recompensa.

        Imaginemos ahora que la manera de describir a los animales es a partir de sus cualidades anat√≥micas. Si tenemos, por ejemplo, una serie de 30 caracter√≠sticas l√≥gicas ---como puede ser presencia o no de plumas, de pelo, si son o no viv√≠paros...--- que los describen, los datos de aprendizaje son los siguientes:
        \begin{itemize}
            \item $\mathcal{X} = \{(x_1, x_2, \dots, x_64) \in \mathbb{Z}_2^30\}$
            \item $\mathcal{Y} = \{P√°jaro, Mam√≠fero, Reptil, Ave, Anfibio\}$
        \end{itemize}

        \emph{Clasificaci√≥n autom√°tica de cartas por distrito postal.}

        Para clasificar autom√°ticamente cartas por distrito postal basta leer el c√≥digo postal escrito en el sobre; esto, evidentemente, se reduce a comprender cada uno de los d√≠gitos escritos.  Estos n√∫meros suelen estar manuscritos, as√≠ que la diversidad de escrituras, tintas y papeles nos impiden intentar abordar este problema por dise√±o ---no conocemos una regla exacta para asignar trazos manuscritos (que pueden tener formas diversas) a su correspondiente d√≠gito---. Adem√°s, podemos tomar una gran muestra de d√≠gitos manuscritos, clasificarlos a mano y usar esta informaci√≥n para intentar aprender bajo qu√© regla se asigna un trazo a un d√≠gito concreto. Este caso es, por tanto, un claro ejemplo de aprendizaje supervisado con clasificaci√≥n multi-etiqueta.

        Imaginemos que tenemos im√°genes escaneadas de d√≠gitos manuscritos, de manera que despu√©s de tratarlas y procesarlas, se reducen s matrices 8x8 ---o vectores de longitud 64--- en las que cada entrada almacena la intensidad del trazo en ese punto, numerada de 0 a 255.
        Los datos de aprendizaje que debemos usar son entonces los siguientes:
        \begin{itemize}
            \item $\mathcal{X} = \{(x_1, x_2, \dots, x_64) \in \mathbb{Z}_256^64\}$
            \item $\mathcal{Y} = \{0, 1, 2, 3, 4, 5, 6, 7, 8, 9\}$
        \end{itemize}

        \emph{Decidir si un determinado √≠ndice del mercado de valores subir√° o bajar√° dentro de un periodo de tiempo fijado.}

        Este problema puede ser abordado con aprendizaje por refuerzo. La situaci√≥n del mercado de valores puede no valer de un a√±o a otro debido a la inestabilidad de las situaciones pol√≠ticas, econ√≥micas y sociales, as√≠ que no es f√°cil generar una muestra de aprendizaje supervisado en la que conozcamos las etiquetas correctas para cada predicci√≥n.

        Sin embargo, s√≠ podemos recolectar predicciones anteriores, su nivel de √©xito ---c√≥mo de cerca estuvieron de la posterior realidad--- y generar una muestra de la forma (situaci√≥n, predicci√≥n, nivel de √©xito de la predicci√≥n), de manera que el algoritmo aprenda c√≥mo de buena o mala ---no exactamente si es la mejor--- es una predicci√≥n. Adem√°s, esta estructura nos permitir√° realimentar el algoritmo con el √©xito de las predicciones que haga una vez se encuentre en producci√≥n, de forma paralela a su funcionamiento.

        Si la situaci√≥n del √≠ndice se puede describir con un n√∫mero real, la predicci√≥n que se hace es otro n√∫mero real y alimentamos el algoritmo con lo que pas√≥ en los √∫ltimos 60 d√≠as, los datos de aprendizaje ser√°n los siguientes:
        \begin{itemize}
            \item $\mathcal{X} = \{(x_1, x_2, \dots, x_30, z) \in \mathbb{R}^30 \times \mathbb{R}\}$
            \item $\mathcal{Y} = [0,1] \texrm{, donde este n√∫mero indica el valor de √©xito de la predicci√≥n.}$
        \end{itemize}
    \end{solucion}


    \begin{ejercicio}
        ¬øCu√°les de los siguientes problemas son m√°s adecuados para una aproximaci√≥n por aprendizaje y cu√°les m√°s adecuados para una aproximaci√≥n por dise√±o? Justificar la decisi√≥n.
        \begin{itemize}
            \item Determinar el ciclo √≥ptimo para las luces de los sem√°foros en un cruce con mucho tr√°fico.
            \item Determinar los ingresos medios de una persona a partir de sus datos de nivel de educaci√≥n, edad, experiencia y estatus social.
            \item Determinar si se debe aplicar una campa√±a de vacunaci√≥n contra una enfermedad.
        \end{itemize}
    \end{ejercicio}

    \begin{solucion}
        \emph{Determinar el ciclo √≥ptimo para las luces de los sem√°foros en un cruce con mucho tr√°fico.}

        Este caso es el m√°s adecuado para una aproximaci√≥n por dise√±o. Podemos medir el nivel de tr√°fico medio en el cruce a lo largo del d√≠a, simular qu√© ocurre con cada uno de los ciclos disponibles y elegir el mejor seg√∫n el criterio que se establezca.

        No tendr√≠a sentido abordar este problema con una aproximaci√≥n por aprendizaje, ya que tenemos una forma anal√≠tica de medir el impacto de cada ajuste de los par√°metros del problema que queremos obtener.

        \emph{Determinar los ingresos medios de una persona a partir de sus datos de nivel de educaci√≥n, edad, experiencia y estatus social.}

        Este caso, sin embargo, es m√°s gi

        \emph{Determinar si se debe aplicar una campa√±a de vacunaci√≥n contra una enfermedad.}
        Niputaidea
    \end{solucion}

    \begin{ejercicio}
        Construir un problema de aprendizaje desde datos para un problema de selecci√≥n de fruta en una explotaci√≥n agraria (ver transparencias de clase). Identificar y describir cada uno de sus elementos formales. Justificar las decisiones.
    \end{ejercicio}

    \begin{ejercicio}
        Suponga un modelo PLA y un dato $x(t)$ mal clasificado respecto de dicho modelo. Probar que la regla de adaptaci√≥n de pesos del PLA es un movimiento en la direcci√≥n correcta para clasificar bien $x(t)$.
    \end{ejercicio}

    \begin{solucion}\footnote{Ejercicio resuelto con la ayuda de los pasos explicados en el Ejercicio 1.3 de \cite{mostafa2012learning}.}

        Sea $(x(t), y(t))$, con $y(t) \in \{-1, +1\}$ la muestra mal clasificada respecto del modelo PLA; esto es, $sign(w^T(t) x(t)) \neq y(t)$ o, dicho de otra manera
        \[
        y(t) sign(w^T(t) x(t)) < 0
        \]

        Probar que la regla de adaptaci√≥n de pesos del PLA es un movimiento en la direcci√≥n correcta para clasificar bien $x(t)$ consiste en determinar que la siguiente iteraci√≥n del algoritmo estar√° m√°s cerca de clasificar bien la muestra; esto es, tenemos que probar lo siguiente:
        \begin{equation}
            y(t) sign(w^T(t+1) x(t)) > y(t) sign(w^T(t) x(t))
            \label{eq:PLA}
        \end{equation}
        donde $w^T(t+1)$ es el vector de pesos que nos da la siguiente iteraci√≥n del algoritmo, y que viene determinado como
        \[
        w(t+1) = w(t) + y(t)x(t)
        \]

        Para probar la desigualdad \ref{eq:PLA} basta trabajar con la parte izquierda y la definici√≥n de $w^T(t+1)$ de la siguiente manera:
        \begin{align*}
            y(t) w^T(t+1) x(t) &= y(t) (w^T(t) + y(t)x(t)) x(t) = \\
            &= (y(t)w^T(t) + x(t)) x(t) = \\
            &= y(t)w^T(t)x(t) + x^2(t) > y(t)w^T(t)x(t)
        \end{align*}
        donde hemos usado que $y(t)^2 = 1$, pues $y(t) \in \{-1, +1\}$ y que $x^2(t) > 0$.

        Hemos probado as√≠ que la regla del PLA permite acercarse a la correcta etiquetaci√≥n de la muestra.
    \end{solucion}


    \begin{ejercicio}
        Considere el enunciado del ejercicio 2 de la secci√≥n FACTIBILIDAD DEL APRENDIZAJE de la relaci√≥n apoyo.
        \begin{itemize}
            \item Si $p = 0.9$, ¬øcu√°l es la probabilidad de que S produzca una hip√≥tesis mejor que C?
            \item ¬øExiste un valor de $p$ para el cual es m√°s probable que C produzca una hip√≥tesis mejor que S?
        \end{itemize}
    \end{ejercicio}


    \begin{ejercicio}
        La desigualdad de Hoeffding modificada nos da una forma de caracterizar el error de generalizaci√≥n con una cota probabil√≠stica
        \[
        \mathbb{P}[\vert E_{out}(g) - E_{in}(g) \vert > \varepsilon] \leq 2 M e^{-2 N^2 \varepsilon}
        \]
        para cualquier $\varepsilon > 0$. Si fijamos $\varepsilon = 0.05$ y queremos que la cota probabil√≠stica $2 M e^{-2 N^2 \varepsilon}$ sea como m√°ximo $0.03$, ¬øcu√°l ser√° el valor m√°s peque√±o de $N$ que verifique estas condiciones si $M = 1$? Repetir para $M = 10$ y para $M = 100$.
    \end{ejercicio}

    \begin{solucion}
        Si imponemos que la cota probabil√≠stica sea menor o igual que un valor $k$, basta despejar $N$ de la desigualdad
        \[
        2 M e^{-2 N^2 \varepsilon} \geq k
        \]
        y estudiar lo que se nos pide. Tenemos entonces:
        \begin{align*}
            2 M e^{-2 N \varepsilon^2} &\leq k \\
            e^{-2 N \varepsilon^2} &\leq \frac{k}{2M} \\
            -2 N \varepsilon^2 &\leq ln(\frac{k}{2M}) \\
            N &\geq \frac{1}{-2\varepsilon^2} ln(\frac{k}{2M})
        \end{align*}

        Es decir, la cota probabil√≠stica ser√° menor o igual que $k$ si y s√≥lo si $N \geq \sqrt{\frac{1}{-2\varepsilon} ln(\frac{k}{2M})}$. Como $N \in \mathbb{N}$, tenemos que el menor $N$ que cumple la condici√≥n para un $M$ dado es exactamente
        \begin{equation}
            N_M = \left\lceil \frac{1}{-2\varepsilon^2} ln\left(\frac{k}{2M}\right) \right\rceil
            \label{eq}
        \end{equation}
        donde $\lceil x \rceil$ es el menor entero mayor o igual que $x$.

        Ahora basta tomar $k = 0.03$, $\varepsilon = 0.05$ y, para $M \in \{1, 10, 100\}$, calcular la expresi√≥n obtenida en \ref{eq}, lo que nos da los siguientes valores:

        \begin{align*}
            N_1 &= 840 \\
            N_{10} &= 1301 \\
            N_{100} &= 1761
        \end{align*}
    \end{solucion}


    \begin{ejercicio}
        Consideremos el modelo de aprendizaje \guillemotleft M-intervalos \guillemotright donde $h \colon \mathbb{R} \to \{‚àí1, +1\}$, y $h(x) = +1$ si el punto est√° dentro de cualquiera de $M$ intervalos arbitrariamente elegidos y ‚àí1 en otro caso. ¬øCu√°l es el m√°s peque√±o punto de ruptura para este conjunto de hip√≥tesis?
    \end{ejercicio}

    \begin{solucion}
        Es claro que $M$ intervalos pueden separar cualquier muestra de $2M$ puntos. Imaginemos, por ejemplo, un tal conjunto de tama√±o $2M$ en el que las muestras con distintas etiquetas se van alternando:
        \[
        +1 \;\;\; -1  \;\;\; +1  \;\;\; -1  \;\;\; \cdots  \;\;\; +1  \;\;\; -1
        \]

        Evidentemente, hay $M$ puntos etiquetados con $+1$, luego basta con \emph{rodear} esos puntos con los $M$ intervalos de los que disponemos para poder separar completamente la muestra.

        De hecho, esta dicotom√≠a es la m√°s \emph{dif√≠cil} de implementar, en el sentido de que necesitamos todos los intervalos disponibles para separarla. Supongamos ahora que intercambiamos dos puntos con etiquetas diferentes de la disposici√≥n anterior. En ese caso necesitar√≠amos s√≥lo $M - 1$ intervalos para implementar la dicotom√≠a. Cualquier otra disposici√≥n resulta en un n√∫mero menor de intervalos necesarios, ya que agrupa puntos con etiquetas iguales bajo un mismo intervalo.

        Concluimos as√≠ que $m_{\mathcal{H}}(2M) = 2^{2M}$.

        Para ver que $2M + 1$ es un punto de ruptura basta probar que no hay ninguna muestra de ese tama√±o de manera que $\mathcal{H}$ sea capaz de separar por completo.

        Consideramos de nuevo la misma muestra anterior, esta vez de tama√±o $2M + 1$, para lo que a√±adimos un $+1$ al final; es decir, tenemos $M + 1$ puntos etiquetados como $+1$ y una dicotom√≠a como la siguiente:
        \[
        +1 \;\;\; -1  \;\;\; +1  \;\;\; -1  \;\;\; \cdots  \;\;\; +1  \;\;\; -1  \;\;\; +1
        \]

        Si nuestro objetivo es implementar con $\mathcal{H}$ la muestra, debemos empezar por la izquierda y, cada vez que encontremos un $+1$, usar un intervalo para etiquetarlo bien. Esto no se puede hacer de otra manera, ya que los $+1$ tienen que estar dentro de un intervalo y los $-1$ fuera. Si seguimos hacia delante, habremos gastado los intervalos al \emph{encerrar} al $M$-√©simo $+1$, luego todo lo que haya a su derecha ser√° etiquetado como $-1$, ya que se queda fuera de un intervalo. El √∫ltimo $+1$, por tanto, ser√° etiquetado incorrectamente.

        Podr√≠amos pensar que esto prueba que existe una √∫nica muestra que $\mathcal{H}$ no puede separar. Sin embargo, cualquier muestra de $2M + 1$ puntos en la recta real es de la forma descrita, y en todas y cada una de ellas existe al menos esta dicotom√≠a que $\mathcal{H}$ no puede implementar.

         Tenemos as√≠ que cualquier muestra de $2M + 1$ puntos tiene al menos una dicotom√≠a que $\mathcal{H}$ no puede implementar; es decir, $k = 2M + 1$ es un punto de ruptura.

        Entonces, como $m_{\mathcal{H}}(2M + 1) < 2^{2M}$ y $m_{\mathcal{H}}(2M) = 2^{2M}$, podemos ya afirmar que $k = 2M + 1$ es el m√°s peque√±o punto de ruptura para este conjunto de hip√≥tesis.
    \end{solucion}


    \begin{ejercicio}
        Suponga un conjunto de $k^*$ puntos $x_1, x_2 , \dots , x_{k^*}$ sobre los cuales la clase $\mathcal{H}$ implementa $< 2^{k^*}$ dicotom√≠as. ¬øCu√°les de las siguientes afirmaciones son correctas?
        \begin{itemize}
            \item $k^*$ es un punto de ruptura.
            \item $k^*$ no es un punto de ruptura.
            \item Todos los puntos de ruptura son estrictamente mayores que $k^*$.
            \item Todos los puntos de ruptura son menores o iguales a $k^*$
            \item No conocemos nada acerca del punto de ruptura.
        \end{itemize}
    \end{ejercicio}

    \begin{solucion}
        En este caso no conocemos nada acerca del punto de ruptura. Por definici√≥n, $k$ es un punto de ruptura si $m_\mathcal{H}(k) < 2^k$. Esto no quiere decir que \emph{exista} una muestra de $k$ puntos para la que $H$ no sea capaz de implementar todas las dicotom√≠as; sino que $\mathcal{H}$ es incapaz de implementar todas las dicotom√≠as \emph{para todas} las muestras de $k$ puntos.
    \end{solucion}


    \begin{ejercicio}
        Para todo conjunto de $k^*$ puntos, $\mathcal{H}$ implementa $< 2^{k^*}$ dicotom√≠as. ¬øCu√°les de las siguientes afirmaciones son correctas?
        \begin{itemize}
            \item $k^*$ es un punto de ruptura.
            \item $k^*$ no es un punto de ruptura.
            \item Todos los $k \geq k^*$ son puntos de ruptura.
            \item Todos los $k < k^*$ son puntos de ruptura.
            \item No conocemos nada acerca del punto de ruptura.
        \end{itemize}
    \end{ejercicio}

    \begin{solucion}
        En este caso ya s√≠ podemos afirmar, usando el mismo argumento que en el ejercicio anterior, que $k^*$ es un punto de ruptura.

        Por otro lado, es evidente que si $k^*$ es un punto de ruptura, $k \geq k^*$ tambi√©n lo es. Esto es claro: si $\mathcal{H}$ es incapaz de separar una muestra de $k^*$ puntos, a√±adir puntos a la muestra no har√° sino hacerla m√°s compleja, luego $\mathcal{H}$ seguir√° siendo incapaz de separarla.

        Por √∫ltimo, poco podemos decir sobre los $k < k^*$. Pueden ser puntos de ruptura, si se da el caso de que $k^*$ no sea el m√°s peque√±o punto de ruptura ---basta usar el mismo argumento que en el p√°rrafo anterior---, o pueden no serlo, como en el caso sencillo del perceptron en el plano, donde sabemos que $k^* = 4$ es un punto de ruptura y $k = 3 < k^*$ no lo es.
    \end{solucion}



    \begin{ejercicio}
        Si queremos mostrar que $k^*$ es un punto de ruptura, ¬øcu√°les de las siguientes afirmaciones nos servir√≠an para ello?:
        \begin{itemize}
            \item Mostrar que existe un conjunto de $k^*$ puntos $x_1, x_2 , \dots , x_{k^*}$ que $\mathcal{H}$ puede separar ---\emph{shatter}---.
            \item Mostrar que $\mathcal{H}$ puede separar cualquier conjunto de $k^*$ puntos.
            \item Mostrar un conjunto de $k^*$ puntos $x_1, x_2 , \dots , x_{k^*}$ que $\mathcal{H}$ no puede separar.
            \item Mostrar que $\mathcal{H}$ no puede separar ning√∫n conjunto de $k^*$ puntos.
            \item Mostrar que $m_\mathcal{H} (k) = 2^{k^*}$
        \end{itemize}
    \end{ejercicio}

    \begin{solucion}
        Por definici√≥n, $k^*$ es un punto de ruptura si $m_\mathcal{H}(k^*) < 2^{k^*}$. Como la funci√≥n de crecimiento est√° definida en t√©rminos del m√°ximo n√∫mero de dicotom√≠as que $H$ puede implementar, podemos concluir que para probar que $k^*$ es un punto de ruptura hay que mostrar que $\mathcal{H}$ no puede separar \emph{ning√∫n} conjunto de $k^*$ puntos.
    \end{solucion}


    \begin{ejercicio}
        Para un conjunto $\mathcal{H}$ con $d_{VC} = 10$, ¬øqu√© tama√±o muestral se necesita ---seg√∫n la cota de generalizaci√≥n--- para tener un 95\% de confianza de que el error de generalizaci√≥n sea como mucho $0.05$?
    \end{ejercicio}

    \begin{ejercicio}
        Consideremos un escenario de aprendizaje simple. Supongamos que la dimensi√≥n de entrada es uno. Supongamos que la variable de entrada $x$ est√° uniformemente distribuida en el intervalo $[-1, 1]$ y el conjunto de datos consiste en 2 puntos $\{x_1, x_2\}$ y que la funci√≥n objetivo es $f(x) = x^2$. Por tanto el conjunto de datos completo es $\mathcal{D} = \{(x_1 , x_1^2), (x_2, x_2^2)\}$. El algoritmo de aprendizaje devuelve la l√≠nea que ajusta estos dos puntos como $g$; es decir, $\mathcal{H}$ consiste en funciones de la forma $h(x) = ax + b$.
        \begin{itemize}
            \item Dar una expresi√≥n anal√≠tica para la funci√≥n promedio $\bar{g}(x)$.
            \item Calcular analiticamente los valores de $E_{out}$, \emph{bias} y \emph{var}.
        \end{itemize}
    \end{ejercicio}


    \section{Bonus}

    \begin{bonus}
        Considere el enunciado del ejercicio 2 de la secci√≥n ERROR Y RUIDO de la relaci√≥n de apoyo.
        \begin{itemize}
            \item Si su algoritmo busca la hip√≥tesis $h$ que minimiza la suma de los valores absolutos de los errores de la muestra,
            \[
            E_{in}(h) = \sum_{n=1}^N \vert h - y_n \vert
            \]
            entonces mostrar que la estimaci√≥n ser√° la mediana de la muestra, $h_{med}$ ---cualquier valor que deje la mitad de la muestra a su derecha y la mitad a su izquierda---.
            \item Suponga que $y_N$ es modificado como $y_N + \varepsilon$, donde $\varepsilon \to \infty$. Obviamente el valor de $y_N$ se convierte en un punto muy alejado de su valor original. ¬øC√≥mo afecta esto a los estimadores dados por $h_{mean}$ y $h_{med}$?
        \end{itemize}
    \end{bonus}



    \begin{bonus}
        Considere el ejercicio 12.
        \begin{itemize}
            \item Describir un experimento que podamos ejecutar para determinar ---num√©ricamente--- $\bar{g}(x)$, $E_{out}$, \emph{bias} y \emph{var}.
            \item Ejecutar el experimento y dar los resultados. Comparar $E_{out}$ con $bias+var$. Dibujar en unos mismos ejes $\bar{g}(x)$, $E_{out}$ y $f(x)$.
        \end{itemize}
    \end{bonus}

    \nocite{*}

% -------------------------- Bibliograf√≠a ------------------------
\bibliographystyle{babplain}
\bibliography{C_01}

\end{document}
