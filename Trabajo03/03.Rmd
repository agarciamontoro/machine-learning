---
title: "Trabajo 3"
author: "Alejandro García Montoro"
date: "2 de junio de 2016"
output: pdf_document
---

```{r setup, include=FALSE}
rm(list=ls())
library(knitr)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
set.seed(1992121)

# Definimos una función para hacer las pausas entre los ejercicios
# Tomada de http://stackoverflow.com/a/15272920/3248221
pausa <- function(){
    print("Presiona [Enter] para continuar...")
    line <- readLines(con = "stdin", n=1)
}
```

# Ejercicio 1

Carguemos primero los datos necesarios para realizar el ejercicio y echémosle un primer vistazo a la base de datos:

```{r}
# Cargamos la librería necesaria para usar la base de datos Auto
# Para usarla, hay que instalar con la orden
# install.packages('ISLR')
library(ISLR)

# Usamos Auto por defecto, evitando así poner el prefijo Auto$
# siempre que queramos acceder a una característica de esa base de datos
attach(Auto)
```

Si ejecutamos las órdenes siguientes

```{r eval=FALSE}
class(Auto)
dim(Auto)
colnames(Auto)
```

podemos obtener información de la forma que tiene nuestra base de datos. Vemos así que tiene forma de `r class(Auto)`, con `r dim(Auto)[1]` filas y `r dim(Auto)[2]` columnas, cuyos nombres son los siguientes: `r colnames(Auto)`.

Podemos eliminar la última columna, que es el nombre del vehículo y la única variable no numérica, para poder trabajar con comodidad más adelante:

```{r}
# Eliminamos la última columna
Auto <- Auto[,seq(ncol(Auto)-1)]
```


## Apartado a

Para visualizar las dependencias entre `mpg` y las otras características podemos usar las funciones `pairs()` y `boxplot()`:

```{r}
# Visualizamos la relación entre todos los pares de variables
pairs(Auto, pch=20, cex=0.2, col="steelblue")
```

Podemos visualizar más de cerca las variables que parecen más relevantes para predecir la variable `mpg`:

```{r}
# Plot para mpg-displacement
plot(displacement, mpg, pch=20, col="steelblue",
     main="Cilindrada")

# Plot para mpg-horsepower
plot(horsepower, mpg, pch=20, col="steelblue",
     main="Potencia")

# Plot para mpg-weight
plot(weight, mpg, pch=20, col="steelblue",
     main="Peso")
```

## Apartado b

Podemos estudiar de forma numérica la correlación entre `mpg` y las demás variables:

```{r}
# Tomamos los valores absolutos de la correlación entre mpg y todas las demás variables,
# sin incluirse a sí misma
corr <- abs(cor(Auto))["mpg",-1]

# Visualizamos el grado de correlación en un gráfico de barras.
# Creamos el gráfico.
bp <- barplot(corr, axes = FALSE, axisnames = FALSE, col = "steelblue",
              main="Correlación entre mpg y las demás variables")

# Añadimos el texto, girado 45 grados.
text(bp, par("usr")[3]-0.02, labels = colnames(Auto[-1]),
     srt = 45, adj = 1, xpd = TRUE)

# Dibujamos los ejes.
axis(2)
```

Como vemos son `cylinders`, `displacement`, `horsepower` y `weight` las variables que más correlación presentan con `mpg`. Sin embargo, vamos a estudiar las tres últimas; la correlación entre la primera y `mpg` es un dato arbitrario que tiene más que ver con la forma de la variable que con la relación entre ambas. Esto se ve claro si ampliamos el gráfico `mpg`-`cylinders`:

```{r}
# Plot para mpg-cylinders
plot(cylinders, mpg, pch=20, col="steelblue",
     main="Número de cilindors")
```

Seleccionamos las variables escogidas:

```{r}
selec <- c("displacement", "horsepower", "weight")
```

## Apartado c

Vamos a crear dos vectores que usaremos para indexar las muestras de entrenamiento y de test:

```{r}
# Vector de índices para la muestra de entrenamiento (80%)
trainIdx  <- sample(nrow(Auto), size=0.8*nrow(Auto))

# Vector de índices para la muestra de test
testIdx   <- setdiff(1:nrow(Auto), trainIdx)
```

## Apartado d

Creamos la variable booleana `mpg01`. En vez de usar los valores simbólicos 1 y -1, usamos unos mucho más expresivos: `True` y `False`. Una vez añadida la variable, partimos los datos en las muestras de entrenamiento y test con los índices calculados anteriormente:

```{r}
# Creamos una nueva variable booleana, mpg01, en función de la mediana,
# y la añadimos a la base de datos
mpg01 <- ifelse(mpg > median(mpg), T, F)
Auto <- data.frame(mpg01, Auto)

# Obtenemos las muestras de entrenamiento y de test
Auto.train <- Auto[trainIdx,]
Auto.test  <- Auto[testIdx,]
```

### Regresión lineal

Para hacer la regresión lineal vamos a usar la función `lm`, que devuelve un modelo lineal `Y~X`, donde `Y` es la variable a predecir y `X` el conjunto de variables predictoras.

Este modelo lineal lo ajustaremos con la muestra de test:

```{r}
# Ajustamos el modelo con los datos de entrenamiento
mod.lin = lm(mpg01~displacement+horsepower+weight, data=Auto.train)
```

Para ver la efectividad del modelo, intentamos predecir la variable `mpg01` con la función `predict` sobre la muestra de test:

```{r}
# Usamos el modelo lineal ajustado para predecir con la muestra de test
mod.lin.pred <- predict(mod.lin, Auto.test, type = "response")
```

Esto nos devuelve en la variable `Auto.mod.lin.pred` las probabilidades predecidas para cada punto de la muestra de test. Por tanto, vamos a asignar el valor `True` a aquellos puntos donde la probabilidad sea mayor al 50% y `False` a los demás:

```{r}
# Si la predicción tiene probabilidad mayor que el 50%,
# asignamos el valor Verdad; en otro caso, asignamos el valor Falso
mod.lin.mpg01 <- ifelse(mod.lin.pred > 0.5, T, F)
```

Para calcular el error ya basta, tan sólo, contar el porcentaje de puntos mal clasificados en la muestra de test:

```{r}
# Calculamos el error como el porcentaje de muestras mal clasificadas
mod.lin.error <- mean(Auto.test$mpg01 != mod.lin.mpg01)
```

De aquí obtenemos que el error producido por este modelo es del `r I(100*mod.lin.error)`%. Podemos ver exactamente cuántos falsos positivos y falsos negativos tenemos; la siguiente tabla, cuyas columnas son los valores predecidos y cuyas filas los reales, resume la efectividad del método:

```{r}
tab <- table(Real=Auto.test$mpg01, Predecido=mod.lin.mpg01)
kable(tab, caption="Regresión lineal")
```

### Vecino más cercano

Para ajustar el modelo de los $k$ vecinos más cercanos necesitamos, primero, normalizar las variables predictoras. Para ello usamos la función `scale()`, que devuelve el conjunto de variables introducido de manera que todas ellas tengan media 0 y varianza 1. Omitimos en este escalado la variable que queremos predecir, `mpg01`, ya que su valor no influirá en las distancias entre los datos, que se mide con las variables predictoras.

El escalado, además lo vamos a hacer de la siguiente manera:

* Escalamos la muestras de entrenamiento.
* Tomamos los valores de medias y varianzas del escalado.
* Escalamos la muestra de test con esos valores.

Esto lo hacemos para que los datos de test no influyan en el proceso de aprendizaje.

```{r}
# Escalado de la muestra de entrenamiento sin la variable mpg01
norm.train <- scale(Auto.train[,-1])

# Escalado de la muesrta de test sin mpg01 y en base al escalado anterior
norm.test <- scale(Auto.test[,-1],
                   center = attributes(norm.train)$"scaled:center",
                   scale = attributes(norm.train)$"scaled:scale")

# Creamos una variable con ambas muestras y la reordenamos según el nombre (número) de las filas
norm.full <- rbind(norm.train, norm.test)
norm.full <- norm.full[order(as.numeric(row.names(norm.full))),]
```

La forma más sencilla de ajustar el modelo y predecir con él es llamar a la función `knn` con no más atributos que las muestras de entrenamiento y test y las clases:

```{r}
# Cargamos la librería class, que contiene los modelos del knn
library(class)

# Predecimos de la forma más directa posible y con el típico valor de k=3
knn.pred <- knn(norm.train, norm.test, Auto.train$mpg01, k=3)

# Calculamos el error
knn.error <- mean(Auto.test$mpg01 != knn.pred)
```

Tenemos así un error de `r I(100*knn.error)`%, que mejora al anterior de regresión lineal. Sin embargo, podemos intentar mejorarlo, ajustando el parámetro $k$ a su óptimo. Esta regularización la podemos hacer con la función `tune.knn` y con el método de validación cruzada:

```{r}
# Necesitamos la librería e1071, que podemos instalar con la orden
# install.packages("e1071")
library(e1071)

# Para la validación cruzada usamos el conjunto completo de datos
# y el conjunto completo de clases
knn.cross <- tune.knn(x = norm.full, y = Auto$mpg01, k = 1:20,
                      tunecontrol = tune.control(sampling = "cross"), cross=10)

# Podemos estudiar visualmente la búsqueda del mejor k:
plot(knn.cross)

# Nos quedamos con el mejor parámetro
knn.k <- knn.cross$best.parameters$k
```

Ajustamos de nuevo el modelo con el valor de $k = `r I(knn.k)`$ obtenido del anterior estudio:

```{r}
# Predecimos con el k calculado
knn.pred <- knn(norm.train, norm.test, Auto.train$mpg01, k = knn.k, prob = T)

# Calculamos de nuevo el error
knn.k.error <- mean(Auto.test$mpg01 != knn.pred)
```

consiguiendo ahora un `r I(100*knn.k.error)`% de error, `r I(100*(knn.error - knn.k.error))` puntos mejor que el anterior.

### Curvas ROC
```{r}
# install.packages("ROCR")
library ( ROCR )
curveROC = function (probabilities, labels, model.knn=F, ...) {
  if(model.knn){
    prob <- attributes(probabilities)$"prob"
    probabilities <- ifelse(probabilities == 0, 1-prob, prob)
  }
  
  prediction = prediction(probabilities, labels)
  performance = performance(prediction, "tpr", "fpr")
  print(performance)
  plot(performance, ...)
}

curveROC(mod.lin.pred, Auto.test$mpg01, col="darkolivegreen", lwd=1.5, main="Curvas ROC")
curveROC(knn.pred, Auto.test$mpg01, model.knn=T, add=T, col="steelblue", lwd=1.5)

legend("bottomright", c("Regresión lineal", "Vecino más cercano"),
       col=c("darkolivegreen", "steelblue"), lwd=1.5)
```

# Ejercicio 2

Cargamos la librería necesaria y estudiamos un poco la base de datos como hicimos antes:


```{r}
# Cargamos la librería necesaria para usar la base de datos Boston
# Para usarla, hay que instalar con la orden
# install.packages('MASS')
library(MASS)

# Usamos Boston por defecto, evitando así poner el prefijo Boston$
# siempre que queramos acceder a una característica de esa base de datos
attach(Boston)
```

Si ejecutamos las órdenes siguientes

```{r eval=FALSE}
class(Boston)
dim(Boston)
colnames(Boston)
```

podemos obtener información de la forma que tiene nuestra base de datos. Vemos así que tiene forma de `r class(Boston)`, con `r dim(Boston)[1]` filas y `r dim(Boston)[2]` columnas, cuyos nombres son los siguientes: `r colnames(Boston)`.

```{r}
# Visualizamos la relación entre todos los pares de variables
pairs(Boston, pch=20, cex=0.2, col="steelblue")
```

Podemos estudiar de forma numérica la correlación entre `crim` y las demás variables:

```{r}
# Tomamos los valores absolutos de la correlación entre crim y todas las demás variables,
# sin incluirse a sí misma
corr <- abs(cor(Boston))["crim",-1]

# Visualizamos el grado de correlación en un gráfico de barras.
# Creamos el gráfico.
bp <- barplot(corr, axes = FALSE, axisnames = FALSE, col = "steelblue",
              main="Correlación entre crim y las demás variables")

# Añadimos el texto, girado 45 grados.
text(bp, par("usr")[3]-0.02, labels = colnames(Boston)[-1],
     srt = 45, adj = 1, xpd = TRUE)

# Dibujamos los ejes.
axis(2)
```

Por último, antes de entrar con el ejercicio en sí, dividimos la muestra en entrenamiento y test como hicimos antes:

```{r}
# Vector de índices para la muestra de entrenamiento (80%)
trainIdx  <- sample(nrow(Boston), size=0.8*nrow(Boston))

# Vector de índices para la muestra de test
testIdx   <- setdiff(1:nrow(Boston), trainIdx)

# Obtenemos las muestras de entrenamiento y de test
Boston.train <- as.matrix(Boston[trainIdx, ])
Boston.test  <- as.matrix(Boston[testIdx, ])
```

## Apartado a

```{r}
# Cargamos la librería glmnet, que debe ser instalada con la orden
# install.packages("glmnet")
library(glmnet)

# Ajustamos un modelo de regresión lineal con regularización y selección de variables.
# El parámetro alpha=1 es la penalización LASSO
mod.lasso <- glmnet ( Boston.train[, -1], Boston.train[,"crim"], alpha = 1)
cvfit = cv.glmnet(Boston.train[, -1], Boston.train[,"crim"])
```

```{r}
#LASSO:
library(glmnet)
lambda=10^seq(-3, -0.2, by = 0.01)

lasso.mod=glmnet(Boston.train[, -1], Boston.train[,"crim"],alpha=1,lambda=lambda)
plot(lasso.mod)

set.seed(1)
cv.out=cv.glmnet(Boston.train[, -1], Boston.train[,"crim"],alpha=1)
#plot(cv.out)
bestlam=cv.out$lambda.min
lasso.pred=predict(lasso.mod,s=bestlam, newx=Boston.test[,-1])
mean((lasso.pred -Boston.test[,"crim"]))
bestlam
```

```{r}
#Do cross validation to find the minimum lambda (the regularization parameter that minimizes the
# mean cross validated error)
lassoreg.cv <- cv.glmnet(Boston.train[, -1], Boston.train[,"crim"])
lassoreg.cv$lambda.min

#Compute the lasso predictions
lassopredo <- predict(lassoreg.cv,Boston.test[,-1],s=lassoreg.cv$lambda.min)

#Alternative way to compute predictions
lassofits<-glmnet(Boston.train[, -1],Boston.train[, "crim"],alpha=1,nlambda=100)
lassopred<-predict(lassofits,Boston.test[,-1],s=lassoreg.cv$lambda.min)

#Coefficients of the lasso for the min lambda
lassocoef<-predict(lassofits,s=lassoreg.cv$lambda.min,type="coefficients")
lassocoef
```


<!-- ```{r Modelos} -->
<!-- modelo <- lm(Auto$mpg ~ Auto$weight, data=Auto) -->
<!-- plot(Auto$weight, Auto$mpg, pch=20) -->
<!-- abline(modelo$coefficients) -->

<!-- summary(modelo) -->
<!-- ``` -->

<!-- ```{r Qué se puede hacer con un modelo} -->
<!-- names(modelo) -->
<!-- methods(class=class(modelo)) -->
<!-- coefficients(modelo) -->
<!-- predict(modelo) -->
<!-- ``` -->

<!-- ```{r Otro modelo} -->
<!-- modelo2 <- lm(Auto$mpg ~ Auto$weight + Auto$displacement + Auto$horsepower, data=Auto) -->

<!-- summary(modelo2) -->
<!-- plot(modelo2) -->
<!-- ``` -->

<!-- ```{r Train-test} -->
<!-- train <- sample(1:nrow(Auto), 100) -->
<!-- test <- Auto[-train,] -->
<!-- ``` -->

<!-- *Apartado 1.d* -->


<!-- ```{r Prediccion modelos} -->
<!-- # Sin decirle nada estmaos usando de nuevo el conjunto de train -->
<!-- probabilidades <- predict(modelo) -->

<!-- # Para usar el test -->
<!-- probabilidades <- predict(modelo, newdata = train) -->

<!-- # Deberíamos poner un ifelse para que si la prob. está por -->
<!-- # debajo de 0.5, se ponga mpg01 a -1; en otro caso, a 1 -->
<!-- ``` -->


<!-- ```{r Tunear el knn} -->
<!-- # Ver http://rstudio-pubs-static.s3.amazonaws.com/16251_6766538f503d45039570e62d94dff635.html -->
<!-- library(e1071) -->
<!-- tune.knn() -->
<!-- ``` -->

<!-- Cómo se escribe nua fórmula para que el modelo devuelva los pesos que nos interesan, modelando lo que queremos: -->

<!-- * Modelo general: `m1 <- lm(Y~.,data=datos)` -->
<!-- * Modelo con columnas especificadas: `m2 <- lm(Y~X1+X2+X3,data=datos)` -->
<!-- * Modelos más complejos: `m1 <- lm(Y~I(X^2)+X2,data=datos)` -->
<!-- * Combinaciones polinómicas: `log gpoly()` -->
<!-- * Para predecir cosas dependientes (p.ej., dos atributos combinados): `lm(Y~X1+X2+X1:X2,data=datos)`, que es equivalente a escribir `lm(Y~X1*X2,data=datos)`. -->
