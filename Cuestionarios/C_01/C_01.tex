\documentclass[a4paper, 11pt]{article}
\usepackage[cuestionario=2]{../estilo}

\begin{document}

    \maketitle

    \section{Ejercicios}

    \begin{ejercicio}
        Identificar, para cada una de las siguientes tareas, qu√© tipo de aprendizaje es el adecuado (supervisado, no supervisado, por refuerzo) y los datos de aprendizaje que deber√≠amos usar. Si una tarea se ajusta a m√°s de un tipo, explicar c√≥mo y describir los datos para cada tipo.
        \begin{itemize}
            \item Categorizar un grupo de animales vertebrados en p√°jaros, mam√≠feros, reptiles, aves y anfibios.
            \item Clasificaci√≥n autom√°tica de cartas por distrito postal.
            \item Decidir si un determinado √≠ndice del mercado de valores subir√° o bajar√° dentro de un periodo de tiempo fijado.
        \end{itemize}
    \end{ejercicio}

    \begin{solucion}
        \emph{Categorizar un grupo de animales vertebrados en p√°jaros, mam√≠feros, reptiles, aves y anfibios.}

        La categorizaci√≥n autom√°tica de un grupo de animales vertebrados en sus diferentes clases puede abordarse como un problema de aprendizaje supervisado. Si tenemos una manera de describir un animal, ya sea con una imagen o, por ejemplo, una descripci√≥n cuantitativa de sus cualidades anat√≥micas, necesitaremos una muestra previamente clasificada para poder entrenar nuestro algoritmo de aprendizaje. Abordar este problema con aprendizaje no supervisado no tendr√≠a sentido, ya que tenemos una forma clara ---aunque no definida anal√≠ticamente, si as√≠ fuera ser√≠a m√°s sensato resolver este problema mediante dise√±o--- de diferenciar entre clases; no usar esa informaci√≥n es perder oportunidades. Por √∫ltimo, el aprendizaje por refuerzo no tiene sentido en este caso; no hay definida una estructura de acti√≥n y recompensa.

        Imaginemos ahora que la manera de describir a los animales es a partir de sus cualidades anat√≥micas. Si tenemos, por ejemplo, una serie de 30 caracter√≠sticas l√≥gicas ---como puede ser presencia o no de plumas, de pelo, si son o no viv√≠paros...--- que los describen, los datos de aprendizaje son los siguientes:
        \begin{itemize}
            \item $\mathcal{X} = \{(x_1, x_2, \dots, x_{64}) \in \mathbb{Z}_2^{30}\}$
            \item $\mathcal{Y} = \{P√°jaro, Mam√≠fero, Reptil, Ave, Anfibio\}$
        \end{itemize}

        \emph{Clasificaci√≥n autom√°tica de cartas por distrito postal.}

        Para clasificar autom√°ticamente cartas por distrito postal basta leer el c√≥digo postal escrito en el sobre; esto, evidentemente, se reduce a comprender cada uno de los d√≠gitos escritos.  Estos n√∫meros suelen estar manuscritos, as√≠ que la diversidad de escrituras, tintas y papeles nos impiden intentar abordar este problema por dise√±o ---no conocemos una regla exacta para asignar trazos manuscritos (que pueden tener formas diversas) a su correspondiente d√≠gito---. Adem√°s, podemos tomar una gran muestra de d√≠gitos manuscritos, clasificarlos a mano y usar esta informaci√≥n para intentar aprender bajo qu√© regla se asigna un trazo a un d√≠gito concreto. Este caso es, por tanto, un claro ejemplo de aprendizaje supervisado con clasificaci√≥n multi-etiqueta.

        Imaginemos que tenemos im√°genes escaneadas de d√≠gitos manuscritos, de manera que despu√©s de tratarlas y procesarlas, se reducen s matrices 8x8 ---o vectores de longitud 64--- en las que cada entrada almacena la intensidad del trazo en ese punto, numerada de 0 a 255.
        Los datos de aprendizaje que debemos usar son entonces los siguientes:
        \begin{itemize}
            \item $\mathcal{X} = \{(x_1, x_2, \dots, x_64) \in \mathbb{Z}_{256}^{64}\}$
            \item $\mathcal{Y} = \{0, 1, 2, 3, 4, 5, 6, 7, 8, 9\}$
        \end{itemize}

        \emph{Decidir si un determinado √≠ndice del mercado de valores subir√° o bajar√° dentro de un periodo de tiempo fijado.}

        Este problema puede ser abordado con aprendizaje por refuerzo. La situaci√≥n del mercado de valores puede no valer de un a√±o a otro debido a la inestabilidad de las situaciones pol√≠ticas, econ√≥micas y sociales, as√≠ que no es f√°cil generar una muestra de aprendizaje supervisado en la que conozcamos las etiquetas correctas para cada predicci√≥n.

        Sin embargo, s√≠ podemos recolectar predicciones anteriores, su nivel de √©xito ---c√≥mo de cerca estuvieron de la posterior realidad--- y generar una muestra de la forma (situaci√≥n, predicci√≥n, nivel de √©xito de la predicci√≥n), de manera que el algoritmo aprenda c√≥mo de buena o mala ---no exactamente si es la mejor--- es una predicci√≥n. Adem√°s, esta estructura nos permitir√° realimentar el algoritmo con el √©xito de las predicciones que haga una vez se encuentre en producci√≥n, de forma paralela a su funcionamiento.

        Si la situaci√≥n del √≠ndice se puede describir con un n√∫mero real, la predicci√≥n que se hace es otro n√∫mero real y alimentamos el algoritmo con lo que pas√≥ en los √∫ltimos 60 d√≠as, los datos de aprendizaje ser√°n los siguientes:
        \begin{itemize}
            \item $\mathcal{X} = \{(x_1, x_2, \dots, x_30, z) \in \mathbb{R}^{30} \times \mathbb{R}\}$
            \item $\mathcal{Y} = [0,1] \textrm{, donde este n√∫mero indica el valor de √©xito de la predicci√≥n.}$
        \end{itemize}
    \end{solucion}


    \begin{ejercicio}
        ¬øCu√°les de los siguientes problemas son m√°s adecuados para una aproximaci√≥n por aprendizaje y cu√°les m√°s adecuados para una aproximaci√≥n por dise√±o? Justificar la decisi√≥n.
        \begin{itemize}
            \item Determinar el ciclo √≥ptimo para las luces de los sem√°foros en un cruce con mucho tr√°fico.
            \item Determinar los ingresos medios de una persona a partir de sus datos de nivel de educaci√≥n, edad, experiencia y estatus social.
            \item Determinar si se debe aplicar una campa√±a de vacunaci√≥n contra una enfermedad.
        \end{itemize}
    \end{ejercicio}

    \begin{solucion}
        \emph{Determinar el ciclo √≥ptimo para las luces de los sem√°foros en un cruce con mucho tr√°fico.}

        Este caso es el m√°s adecuado para una aproximaci√≥n por dise√±o. Podemos medir el nivel de tr√°fico medio en el cruce a lo largo del d√≠a, simular qu√© ocurre con cada uno de los ciclos disponibles y elegir el mejor seg√∫n el criterio que se establezca.

        No tendr√≠a sentido abordar este problema con una aproximaci√≥n por aprendizaje, ya que tenemos una forma anal√≠tica de medir el impacto de cada ajuste de los par√°metros del problema que queremos obtener.

        \emph{Determinar los ingresos medios de una persona a partir de sus datos de nivel de educaci√≥n, edad, experiencia y estatus social.}

        Este caso, sin embargo, es m√°s adecuado para una aproximaci√≥n por aprendizaje. No existe una expresi√≥n anal√≠tica que nos diga, dados los datos de educaci√≥n, edad, experiencia y estatus social, los ingresos medios de una persona. Sin embargo, es evidente que entre estas variables existe una relaci√≥n.

        Estamos ante un problema que requiere claramente de una aproximaci√≥n por aprendizaje, en la que tendremos que tomar una muestra lo suficientemente amplia de personas, analizar sus datos e intentar aprender la relaci√≥n que existe entre ellos.

        \emph{Determinar si se debe aplicar una campa√±a de vacunaci√≥n contra una enfermedad.}
        Las enfermedades son diversas y tienen comportamientos muy inestables. Aunque quiz√°s existan par√°metros anal√≠ticos para intentar una aproximaci√≥n por dise√±o, en este caso parece m√°s sensato tambi√©n intentar abordar el problema mediante aprendizaje.

        Podr√≠amos estudiar todos los casos documentados de enfermedades, analizar sus atributos, determinar si se aplic√≥ o  no una campa√±a de vacunaci√≥n y c√≥mo de exitosa fue la decisi√≥n. De esta manera, podr√≠amos intentar aprender qu√© hacer ante la nueva enfermedad intentando aprender una relaci√≥n entre sus atributos y los de enfermedades ya tratadas.
    \end{solucion}

    \begin{ejercicio}
        Construir un problema de aprendizaje desde datos para un problema de selecci√≥n de fruta en una explotaci√≥n agraria ---ver transparencias de clase---. Identificar y describir cada uno de sus elementos formales. Justificar las decisiones.
    \end{ejercicio}

    \begin{solucion}
        En este ejercicio tenemos que identificar $\mathcal{X}$, el conjunto de caracter√≠sticas medidas; $\mathcal{Y}$, el conjunto de etiquetas que podemos asignar a cada muestra; $\matcahl{D}$, el conjunto de muestras de entrenamiento y $f$, la funci√≥n objetivo.

        En el problema queremos seleccionar qu√© fruta est√° en su punto √≥ptimo de madurez y cu√°l no ---ya que queremos escoger el producto que mejor salida tenga en el mercado despu√©s---. Si codificamos \emph{maduro} como +1 y \emph{no maduro} como -1, el conjunto de etiquetas ser√° el siguiente:
        \[
        \mathcal{Y} = \{+1, -1\}
        \]

        Imaginemos ahora que el experto nos ha informado de que las siguientes caracter√≠sticas f√≠sicas son las que determinan la madurez de una pieza de fruta en concreto:
        \begin{itemize}
            \item Tama√±o.
            \item Color.
        \end{itemize}

        Estas caracter√≠sticas las mediremos de la siguiente forma:
        \begin{itemize}
            \item El tama√±o lo mediremos de forma continua, luego se mueve en $\mathbb{R}^+$
            \item El color lo mediremos con im√°genes de las piezas de fruta, analizando despu√©s la media de los p√≠xeles pertenecientes a la fruta en una escala de 256 valores en cada uno de los tres canales de color usuales: rojo, verde y azul. Por tanto, esta medida se mueve en $\mathbb{Z}_{256}^3$.
        \end{itemize}

        As√≠, concluimos que el conjunto de caracter√≠sticas es el siguiente:
        \[
        \mathcal{X} = \mathbb{R}^+ \times \mathbb{Z}_{256}^3
        \]

        Si en nuestra visita a  la huerta tomamos 100 muestras de mangos, medimos su tama√±o y color y analizamos, con ayuda del experto, si est√°n o no maduros, nuestro conjunto de entrenamiento ser√° de la siguiente forma:
        \[
        \mathcal{D} = \{(x_i, y_i) \; i = 1, 2, \dots, 100 \;/ x_i \in \mathcal{X}, y_i\in\mathcal{Y} \}
        \]

        La finalidad del aprendizaje ser√° encontrar la funci√≥n objetivo, fjia pero desconocida, siguiente:
        \[
        f \colon \mathcal{X} \to \mathcal{Y}
        \]

        Tenemos as√≠ todos los elementos formales del aprendizaje. Para desarrollar el modelo completo, tendremos que seleccionar $\mathcal{H}$, el conjunto de hip√≥tesis ---esto deber√≠amos hacerlo antes de conocer las muestras--- y $\mathcal{A}$, el algoritmo de aprendizaje.
    \end{solucion}

    \begin{ejercicio}
        Suponga un modelo PLA y un dato $x(t)$ mal clasificado respecto de dicho modelo. Probar que la regla de adaptaci√≥n de pesos del PLA es un movimiento en la direcci√≥n correcta para clasificar bien $x(t)$.
    \end{ejercicio}

    \begin{solucion}\footnote{Ejercicio resuelto con la ayuda de los pasos explicados en el Ejercicio 1.3 de \cite{mostafa2012learning}.}

        Sea $(x(t), y(t))$, con $y(t) \in \{-1, +1\}$ la muestra mal clasificada respecto del modelo PLA; esto es, $sign(w^T(t) x(t)) \neq y(t)$ o, dicho de otra manera
        \[
        y(t) sign(w^T(t) x(t)) < 0
        \]

        Probar que la regla de adaptaci√≥n de pesos del PLA es un movimiento en la direcci√≥n correcta para clasificar bien $x(t)$ consiste en determinar que la siguiente iteraci√≥n del algoritmo estar√° m√°s cerca de clasificar bien la muestra; esto es, tenemos que probar lo siguiente:
        \begin{equation}
            y(t) sign(w^T(t+1) x(t)) > y(t) sign(w^T(t) x(t))
            \label{eq:PLA}
        \end{equation}
        donde $w^T(t+1)$ es el vector de pesos que nos da la siguiente iteraci√≥n del algoritmo, y que viene determinado como
        \[
        w(t+1) = w(t) + y(t)x(t)
        \]

        Para probar la desigualdad \ref{eq:PLA} basta trabajar con la parte izquierda y la definici√≥n de $w^T(t+1)$ de la siguiente manera:
        \begin{align*}
            y(t) w^T(t+1) x(t) &= y(t) (w^T(t) + y(t)x(t)) x(t) = \\
            &= (y(t)w^T(t) + x(t)) x(t) = \\
            &= y(t)w^T(t)x(t) + x^2(t) > y(t)w^T(t)x(t)
        \end{align*}
        donde hemos usado que $y(t)^2 = 1$, pues $y(t) \in \{-1, +1\}$ y que $x^2(t) > 0$.

        Hemos probado as√≠ que la regla del PLA permite acercarse al correcto etiquetado de la muestra.
    \end{solucion}


    \begin{ejercicio}
        Considere el enunciado del ejercicio 2 de la secci√≥n FACTIBILIDAD DEL APRENDIZAJE de la relaci√≥n apoyo.
        \begin{itemize}
            \item Si $p = 0.9$, ¬øcu√°l es la probabilidad de que S produzca una hip√≥tesis mejor que C?
            \item ¬øExiste un valor de $p$ para el cual es m√°s probable que C produzca una hip√≥tesis mejor que S?
        \end{itemize}
    \end{ejercicio}

    \begin{solucion}
        \emph{Si $p = 0.9$, ¬øcu√°l es la probabilidad de que S produzca una hip√≥tesis mejor que C?}

        En el ejercicio citado se intenta aprender la funci√≥n
        \[
            f \colon \mathcal{X} = \mathbb{R} \to \mathcal{Y} = \{-1, +1\}
        \]
        con un conjunto de hip√≥tesis $\mathcal{H} = \{h_1 \equiv +1, h_2 \equiv -1 \}$. El algoritmo S elige la hip√≥tesis que mejor ajusta los datos y el C justo la contraria. Adem√°s, se asume que todos los ejemplos en $\mathcal{D}$ tienen $y_n = +1$.

        Supuesto en este ejercicio que $p = P[f(x) = +1] = 0.9$, podemos estudiar cu√°les es la probabilidad de que S produzca una hip√≥tesis mejor que C estudiando la siguiente probabilidad:
        \[
            P[E_{out}^S < E_{out}^C]
        \]
        donde $E_{out}^S$ indica el error fuera de la muestra de la hip√≥tesis producida por S y $E_{out}^C$ el error fuera de la muestra de la hip√≥tesis producida por C.

        Estos errores fuera de la muestra se corresponden con la probabilidad de que la hip√≥tesis producida \emph{no} sea la funci√≥n objetivo $f$; es decir, tenemos la siguiente expresi√≥n:
        \[
            P[E_{out}^S < E_{out}^C] = P[ P[f \neq h_S] < P[f \neq h_C] ]
        \]
        donde $h_S$ es la hip√≥tesis producida por $S$ y $h_C$ la producida por $C$.

        Como por hip√≥tesis todas las muestras en $\mathcal{D}$ est√°n etiquetadas como +1, $S$ elegir√° la funci√≥n $h_1$ y $C$ la $h_2$. Por tanto, la expresi√≥n anterior se puede escribir como:
        \[
            P[E_{out}^S < E_{out}^C] = P[ P[f \neq +1] < P[f \neq -1] ]
        \]

        Pero por hip√≥tesis sabemos que $P[f(x) = +1] = p = 0.9$. Por tanto, tenemos que $P[f(x) \neq +1] = 1 - p = 0.1$ y $P[f(x) \neq -1] = P[f(x) = +1] = p = 0.9$. Hemos reducido nuestra expresi√≥n a lo siguiente, que ya podemos calcular:
        \begin{equation}
            P[E_{out}^S < E_{out}^C] = P[1-p < p] = P[ 0.1 < 0.9 ] = 1
            \label{eq:prob}
        \end{equation}
        ya que $0.1$ es siempre menor estricto que $0.9$.

        Hemos probado entonces que si $p = 0.9$, es seguro que S producir√° una hip√≥tesis mejor que C.

        \emph{¬øExiste un valor de $p$ para el cual es m√°s probable que C produzca una hip√≥tesis mejor que S?}

        Siguiendo el mismo razonamiento, llegamos a la expresi√≥n \ref{eq:prob}. Sin embargo, como queremos ver cu√°ndo es m√°s probable que C produzca una hip√≥tesis mejor que S, tenemos que darle la vuelta a la desigualdad. Nuestro problema se reduce entonces a determinar el $p$ de manera que
        \[
        P[E_{out}^S > E_{out}^C] = P[1-p > p]
        \]
        Operando con la desigualdad $1-p > p$ tenemos
        \begin{align*}
            1 - p &> p \\
            1  &> 2p \\
            p &< \frac{1}{2}
        \end{align*}

        Podemos concluir entonces que es m√°s pobable que C produza una hip√≥tesis mejor que S si y s√≥lo si $p < 0.5$.
    \end{solucion}


    \begin{ejercicio}
        La desigualdad de Hoeffding modificada nos da una forma de caracterizar el error de generalizaci√≥n con una cota probabil√≠stica
        \[
        \mathbb{P}[\vert E_{out}(g) - E_{in}(g) \vert > \varepsilon] \leq 2 M e^{-2 N^2 \varepsilon}
        \]
        para cualquier $\varepsilon > 0$. Si fijamos $\varepsilon = 0.05$ y queremos que la cota probabil√≠stica $2 M e^{-2 N^2 \varepsilon}$ sea como m√°ximo $0.03$, ¬øcu√°l ser√° el valor m√°s peque√±o de $N$ que verifique estas condiciones si $M = 1$? Repetir para $M = 10$ y para $M = 100$.
    \end{ejercicio}

    \begin{solucion}
            wSi imponemos que la cota probabil√≠stica sea menor o igual que un valor $k$, basta despejar $N$ de la desigualdad
        \[
        2 M e^{-2 N \varepsilon^2} \geq k
        \]
        y estudiar lo que se nos pide. Tenemos entonces:
        \begin{align*}
            2 M e^{-2 N \varepsilon^2} &\leq k \\
            e^{-2 N \varepsilon^2} &\leq \frac{k}{2M} \\
            -2 N \varepsilon^2 &\leq ln(\frac{k}{2M}) \\
            N &\geq \frac{1}{-2\varepsilon^2} ln(\frac{k}{2M})
        \end{align*}

        Es decir, la cota probabil√≠stica ser√° menor o igual que $k$ si y s√≥lo si $N \geq \sqrt{\frac{1}{-2\varepsilon} ln(\frac{k}{2M})}$. Como $N \in \mathbb{N}$, tenemos que el menor $N$ que cumple la condici√≥n para un $M$ dado es exactamente
        \begin{equation}
            N_M = \left\lceil \frac{1}{-2\varepsilon^2} ln\left(\frac{k}{2M}\right) \right\rceil
            \label{eq}
        \end{equation}
        donde $\lceil x \rceil$ es el menor entero mayor o igual que $x$.

        Ahora basta tomar $k = 0.03$, $\varepsilon = 0.05$ y, para $M \in \{1, 10, 100\}$, calcular la expresi√≥n obtenida en \ref{eq}, lo que nos da los siguientes valores:

        \begin{align*}
            N_1 &= 840 \\
            N_{10} &= 1301 \\
            N_{100} &= 1761
        \end{align*}
    \end{solucion}


    \begin{ejercicio}
        Consideremos el modelo de aprendizaje \guillemotleft M-intervalos \guillemotright donde $h \colon \mathbb{R} \to \{‚àí1, +1\}$, y $h(x) = +1$ si el punto est√° dentro de cualquiera de $M$ intervalos arbitrariamente elegidos y ‚àí1 en otro caso. ¬øCu√°l es el m√°s peque√±o punto de ruptura para este conjunto de hip√≥tesis?
    \end{ejercicio}

    \begin{solucion}
        Es claro que $M$ intervalos pueden separar cualquier muestra de $2M$ puntos. Imaginemos, por ejemplo, un tal conjunto de tama√±o $2M$ en el que las muestras con distintas etiquetas se van alternando:
        \[
        +1 \;\;\; -1  \;\;\; +1  \;\;\; -1  \;\;\; \cdots  \;\;\; +1  \;\;\; -1
        \]

        Evidentemente, hay $M$ puntos etiquetados con $+1$, luego basta con \emph{rodear} esos puntos con los $M$ intervalos de los que disponemos para poder separar completamente la muestra.

        De hecho, esta dicotom√≠a es la m√°s \emph{dif√≠cil} de implementar, en el sentido de que necesitamos todos los intervalos disponibles para separarla. Supongamos ahora que intercambiamos dos puntos con etiquetas diferentes de la disposici√≥n anterior. En ese caso necesitar√≠amos s√≥lo $M - 1$ intervalos para implementar la dicotom√≠a. Cualquier otra disposici√≥n resulta en un n√∫mero menor de intervalos necesarios, ya que agrupa puntos con etiquetas iguales bajo un mismo intervalo.

        Concluimos as√≠ que $m_{\mathcal{H}}(2M) = 2^{2M}$.

        Para ver que $2M + 1$ es un punto de ruptura basta probar que no hay ninguna muestra de ese tama√±o de manera que $\mathcal{H}$ sea capaz de separar por completo.

        Consideramos de nuevo la misma muestra anterior, esta vez de tama√±o $2M + 1$, para lo que a√±adimos un $+1$ al final; es decir, tenemos $M + 1$ puntos etiquetados como $+1$ y una dicotom√≠a como la siguiente:
        \[
        +1 \;\;\; -1  \;\;\; +1  \;\;\; -1  \;\;\; \cdots  \;\;\; +1  \;\;\; -1  \;\;\; +1
        \]

        Si nuestro objetivo es implementar con $\mathcal{H}$ la muestra, debemos empezar por la izquierda y, cada vez que encontremos un $+1$, usar un intervalo para etiquetarlo bien. Esto no se puede hacer de otra manera, ya que los $+1$ tienen que estar dentro de un intervalo y los $-1$ fuera. Si seguimos hacia delante, habremos gastado los intervalos al \emph{encerrar} al $M$-√©simo $+1$, luego todo lo que haya a su derecha ser√° etiquetado como $-1$, ya que se queda fuera de un intervalo. El √∫ltimo $+1$, por tanto, ser√° etiquetado incorrectamente.

        Podr√≠amos pensar que esto prueba que existe una √∫nica muestra que $\mathcal{H}$ no puede separar. Sin embargo, cualquier muestra de $2M + 1$ puntos en la recta real es de la forma descrita, y en todas y cada una de ellas existe al menos esta dicotom√≠a que $\mathcal{H}$ no puede implementar.

         Tenemos as√≠ que cualquier muestra de $2M + 1$ puntos tiene al menos una dicotom√≠a que $\mathcal{H}$ no puede implementar; es decir, $k = 2M + 1$ es un punto de ruptura.

        Entonces, como $m_{\mathcal{H}}(2M + 1) < 2^{2M}$ y $m_{\mathcal{H}}(2M) = 2^{2M}$, podemos ya afirmar que $k = 2M + 1$ es el m√°s peque√±o punto de ruptura para este conjunto de hip√≥tesis.
    \end{solucion}


    \begin{ejercicio}
        Suponga un conjunto de $k^*$ puntos $x_1, x_2 , \dots , x_{k^*}$ sobre los cuales la clase $\mathcal{H}$ implementa $< 2^{k^*}$ dicotom√≠as. ¬øCu√°les de las siguientes afirmaciones son correctas?
        \begin{itemize}
            \item $k^*$ es un punto de ruptura.
            \item $k^*$ no es un punto de ruptura.
            \item Todos los puntos de ruptura son estrictamente mayores que $k^*$.
            \item Todos los puntos de ruptura son menores o iguales a $k^*$
            \item No conocemos nada acerca del punto de ruptura.
        \end{itemize}
    \end{ejercicio}

    \begin{solucion}
        En este caso no conocemos nada acerca del punto de ruptura. Por definici√≥n, $k$ es un punto de ruptura si $m_\mathcal{H}(k) < 2^k$. Esto no quiere decir que \emph{exista} una muestra de $k$ puntos para la que $H$ no sea capaz de implementar todas las dicotom√≠as; sino que $\mathcal{H}$ es incapaz de implementar todas las dicotom√≠as \emph{para todas} las muestras de $k$ puntos.
    \end{solucion}


    \begin{ejercicio}
        Para todo conjunto de $k^*$ puntos, $\mathcal{H}$ implementa $< 2^{k^*}$ dicotom√≠as. ¬øCu√°les de las siguientes afirmaciones son correctas?
        \begin{itemize}
            \item $k^*$ es un punto de ruptura.
            \item $k^*$ no es un punto de ruptura.
            \item Todos los $k \geq k^*$ son puntos de ruptura.
            \item Todos los $k < k^*$ son puntos de ruptura.
            \item No conocemos nada acerca del punto de ruptura.
        \end{itemize}
    \end{ejercicio}

    \begin{solucion}
        En este caso ya s√≠ podemos afirmar, usando el mismo argumento que en el ejercicio anterior, que $k^*$ es un punto de ruptura.

        Por otro lado, es evidente que si $k^*$ es un punto de ruptura, $k \geq k^*$ tambi√©n lo es. Esto es claro: si $\mathcal{H}$ es incapaz de separar una muestra de $k^*$ puntos, a√±adir puntos a la muestra no har√° sino hacerla m√°s compleja, luego $\mathcal{H}$ seguir√° siendo incapaz de separarla.

        Por √∫ltimo, poco podemos decir sobre los $k < k^*$. Pueden ser puntos de ruptura, si se da el caso de que $k^*$ no sea el m√°s peque√±o punto de ruptura ---basta usar el mismo argumento que en el p√°rrafo anterior---, o pueden no serlo, como en el caso sencillo del perceptron en el plano, donde sabemos que $k^* = 4$ es un punto de ruptura y $k = 3 < k^*$ no lo es.
    \end{solucion}



    \begin{ejercicio}
        Si queremos mostrar que $k^*$ es un punto de ruptura, ¬øcu√°les de las siguientes afirmaciones nos servir√≠an para ello?:
        \begin{itemize}
            \item Mostrar que existe un conjunto de $k^*$ puntos $x_1, x_2 , \dots , x_{k^*}$ que $\mathcal{H}$ puede separar ---\emph{shatter}---.
            \item Mostrar que $\mathcal{H}$ puede separar cualquier conjunto de $k^*$ puntos.
            \item Mostrar un conjunto de $k^*$ puntos $x_1, x_2 , \dots , x_{k^*}$ que $\mathcal{H}$ no puede separar.
            \item Mostrar que $\mathcal{H}$ no puede separar ning√∫n conjunto de $k^*$ puntos.
            \item Mostrar que $m_\mathcal{H} (k) = 2^{k^*}$
        \end{itemize}
    \end{ejercicio}

    \begin{solucion}
        Por definici√≥n, $k^*$ es un punto de ruptura si $m_\mathcal{H}(k^*) < 2^{k^*}$. Como la funci√≥n de crecimiento est√° definida en t√©rminos del m√°ximo n√∫mero de dicotom√≠as que $H$ puede implementar, podemos concluir que para probar que $k^*$ es un punto de ruptura hay que mostrar que $\mathcal{H}$ no puede separar \emph{ning√∫n} conjunto de $k^*$ puntos.
    \end{solucion}


    \begin{ejercicio}
        Para un conjunto $\mathcal{H}$ con $d_{VC} = 10$, ¬øqu√© tama√±o muestral se necesita ---seg√∫n la cota de generalizaci√≥n--- para tener un 95\% de confianza de que el error de generalizaci√≥n sea como mucho $0.05$?
    \end{ejercicio}

    \begin{solucion}
        La cota de generalizaci√≥n nos dice que, para tener una confianza del $1-\delta$ de que el error de generalizaci√≥n sea como mucho $\varepsilon$, tenemos que tomar un n√∫mero de muestras $N$ tal que cumpla la siguiente desigualdad:
        \[
        N \geq \frac{8}{\varepsilon^2} ln(\frac{4 (2N)^{d_{VC}} + 4}{\delta})
        \]
        Una forma poco elegante, pero r√°pida de implementar en este caso, de conseguir tal n√∫mero es iterando sobre $N$ y comprobar si la desigualdad se satisface. El siguiente script en Python nos es suficiente para determinar el menor $N$ necesario para tener un 95\% de confianza ---como $1-\delta = 0.95$, entonces $\delta = 0.05$--- de que el error de generalizaci√≥n sea como mucho $\varepsilon = 0.05$:

        \begin{lstlisting}
        from math import log

        # Define las constantes del ejercicio
        eps = 0.05
        delta = 0.05
        dVC = 10

        # Iteramos desde 1 hasta 500.000
        for N in range(1, 500000):
            rhs = (8 / eps**2) * log((4*(2*N)**dVC + 4) / delta)

        if(N >= rhs):
            # Si se cumple la desigualdad, imprime N y sal del bucle
            print(N)
            break
        \end{lstlisting}

        As√≠, obtenemos que el n√∫mero de muestras tiene que ser mayor o igual que 452957.
    \end{solucion}

    \begin{ejercicio}
        Consideremos un escenario de aprendizaje simple. Supongamos que la dimensi√≥n de entrada es uno. Supongamos que la variable de entrada $x$ est√° uniformemente distribuida en el intervalo $[-1, 1]$ y el conjunto de datos consiste en 2 puntos $\{x_1, x_2\}$ y que la funci√≥n objetivo es $f(x) = x^2$. Por tanto el conjunto de datos completo es $\mathcal{D} = \{(x_1 , x_1^2), (x_2, x_2^2)\}$. El algoritmo de aprendizaje devuelve la l√≠nea que ajusta estos dos puntos como $g$; es decir, $\mathcal{H}$ consiste en funciones de la forma $h(x) = ax + b$.
        \begin{itemize}
            \item Dar una expresi√≥n anal√≠tica para la funci√≥n promedio $\bar{g}(x)$.
            \item Calcular anal√≠ticamente los valores de $E_{out}$, \emph{bias} y \emph{var}.
        \end{itemize}
    \end{ejercicio}

    \begin{solucion}
        \emph{Dar una expresi√≥n anal√≠tica para la funci√≥n promedio $\bar{g}(x)$.}

        La funci√≥n promedio se puede calcular como sigue:
        \[
        \bar{g}(x) = \mathbb{E}_{\mathcal{D}_n}[g^{\mathcal{D}_n}(x)] \approx \frac{1}{K} \sum_{n=1}^K g^{\mathcal{D}_n}(x)
        \]
        donde $g^{\mathcal{D}_n}(x)$ es la funci√≥n que devuelve el algoritmo respecto del n-√©simo conjunto de datos $\mathcal{D}_n$.

        Llamando $\mathcal{D}_n =\{(a_n, a_n^2), (b_n, b_n^2)\}$, sabemos la expresi√≥n expl√≠cita de $g^{\mathcal{D}_n}(x)$, ya que no es m√°s que la recta :
        \[
        g^{\mathcal{D}_n}(x) = m_n x + c_n
        \]
        donde $m_n$ es la pendiente de la recta y $c_n$ el punto de corte con el eje vertical; es decir:
        \begin{align*}
            m_n &= \frac{b_n^2 - a_n^2}{b_n - a_n} \\
            c_n &= a_n^2 - \frac{a_n (b_n^2-a_n^2)}{b_n - a_n}
        \end{align*}

        Tenemos entonces la siguiente expresi√≥n de la funci√≥n promedio:
        \begin{equation}
            \bar{g}(x) \approx \frac{1}{K} \sum_{n=1}^K (m_n x + c_n) = \frac{1}{K} \left( \sum_{n=1}^K m_n \right) x  +  \frac{1}{K} \sum_{n=1}^K c_n
            \label{eq:barg}
        \end{equation}

        Esto es, la funci√≥n promedio es aproximadamente la recta cuya pendiente es la media de las pendientes entre cada par de puntos generados y cuyo corte con el eje vertical es la media de los cortes con el eje vertical de las rectas generadas para cada par de puntos.

        El \emph{aproximadamente} lo podemos eliminar, y por tanto tener una igualdad, si consideramos todos los conjuntos $\mathcal{D}_n$ posibles. Como los datos est√°n uniformemente distribuidos en $[-1, 1]$, tanto la media de las pendientes como la media de los puntos de corte ser√° 0 ---ya que la media de una muestra uniforme en $[-1,1]$ y las operaciones en $m_n$ y $c_n$ no alteran la media---.

        Podemos concluir entonces que
        \[
        \bar{g}(x) = 0x + 0 = 0 \;\;\;\; \forall x
        \]
    \end{solucion}


    \section{Bonus}

    \begin{bonus}
        Considere el enunciado del ejercicio 2 de la secci√≥n ERROR Y RUIDO de la relaci√≥n de apoyo.
        \begin{itemize}
            \item Si su algoritmo busca la hip√≥tesis $h$ que minimiza la suma de los valores absolutos de los errores de la muestra,
            \[
            E_{in}(h) = \sum_{n=1}^N \vert h - y_n \vert
            \]
            entonces mostrar que la estimaci√≥n ser√° la mediana de la muestra, $h_{med}$ ---cualquier valor que deje la mitad de la muestra a su derecha y la mitad a su izquierda---.
            \item Suponga que $y_N$ es modificado como $y_N + \varepsilon$, donde $\varepsilon \to \infty$. Obviamente el valor de $y_N$ se convierte en un punto muy alejado de su valor original. ¬øC√≥mo afecta esto a los estimadores dados por $h_{mean}$ y $h_{med}$?
        \end{itemize}
    \end{bonus}



    \begin{bonus}
        Considere el ejercicio 12.
        \begin{itemize}
            \item Describir un experimento que podamos ejecutar para determinar ---num√©ricamente--- $\bar{g}(x)$, $E_{out}$, \emph{bias} y \emph{var}.
            \item Ejecutar el experimento y dar los resultados. Comparar $E_{out}$ con $bias+var$. Dibujar en unos mismos ejes $\bar{g}(x)$, $E_{out}$ y $f(x)$.
        \end{itemize}
    \end{bonus}

    \begin{solucion}
        Podemos desarrollar un experimento sencillo atendiendo a la expresi√≥n de la funci√≥n promedio obtenida en \ref{eq:barg}. As√≠, basta tomar una muestra lo suficientemente grande de una distribuci√≥n uniforme en el intervalo $[-1,+1]$, tomar sus cuadrados y generar $K$ conjuntos $\mathcal{D}_n$.

        Con cada uno de estos conjuntos podemos calcular $g^{\mathcal{D}_n}(x)$; esto es, la pendiente y punto de corte con el eje vertical de la recta obtenida con los dos puntos de $\mathcal{D}_n$. Por \ref{eq:barg}, basta luego tomar la media de las pendientes y de los puntos de corte y reconstruir as√≠ $\bar{g}(x)$.
    \end{solucion}

    \nocite{*}

% -------------------------- Bibliograf√≠a ------------------------
\bibliographystyle{babplain}
\bibliography{C_01}

\end{document}
